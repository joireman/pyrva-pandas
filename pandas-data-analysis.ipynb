{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas for Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Pandas Documentation](http://pandas.pydata.org/pandas-docs/stable/) : latest version is 2.2.2 as of April 18, 2024\n",
    "- [Python for Data Analysis](https://www.amazon.com/Python-Data-Analysis-Wrangling-Jupyter-dp-109810403X/dp/109810403X/ref=dp_ob_title_bk) - original book about pandas, now in 3rd edition (Wes McKinney - creator)\n",
    "- [Data analysis in Python with pandas](https://www.youtube.com/watch?v=w26x-z-BdWQ) - YouTube training video from PyCon (Wes McKinney)\n",
    "- [Data Analysis with Python and Pandas](https://www.udemy.com/course/data-analysis-with-pandas/?couponCode=LETSLEARNNOWPP) - Udemy training course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.2.2\n",
      "numpy version 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# plot all graphs inline\n",
    "%matplotlib inline    \n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Series` is a 1D data structure that can contain any data of the same type.  A minimal `Series` constructor looks like:\n",
    "```\n",
    "s = pd.Series(data)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but we are going to use the slightly more useful constructor: \n",
    "```\n",
    "s = pd.Series(data, index, name)\n",
    "```\n",
    "here `data` can be lots of things, a list, an `np.ndarray`, a Python `dict` or a scalar value.  The `index` is not required, but if it is provided it must be the same length as the provided data.  If an `index` is not provided a zero based integer index is created based on the size of the data.  If input is a Python `dict` the key values are used as the index labels.\n",
    "\n",
    "The `name` parameter is not needed but can be used to label the entire `Series`, if the named `Series` is then used to build a `DataFrame` (see below) the name will be used as the column label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "aser = pd.Series([1,2,3,4,5], index=list('abcdd'), name='A')\n",
    "aser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: the index does not need to be unique\n",
    "aser.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series acts much like a standard numpy array with a few additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f'The length of the Series is: {len(aser)}')\n",
    "print(f'The size attribute also gives the same result: {aser.size}')\n",
    "print(f\"You can total up the values in the series: {aser.sum()}\")\n",
    "print(f\"  Or maybe you are in a factorial state of mind! {aser.product()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcser = aser.pct_change()\n",
    "pcser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Series acts like an array or list for selection\n",
    "aser[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Can also select using labels, kind of like a dict\n",
    "aser['b':'d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Can operate on a series just like a numpy array\n",
    "aser*2 + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References for efficiency\n",
    "\n",
    "**Pandas doesn't implicitly copy any data behind your back**, the library really forces you to declare your intentions.  Series can be assigned to other variables but these are only references, using them touches the original series, similar to other Python references.  If you want a copy you need to use the `copy()` method, this has a cost that `pandas` doesn't want to pay without you agreeing.   It is similar for functions which could modify your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort in descending order\n",
    "aser.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original series unaffected\n",
    "aser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign output to new variable or sort in place\n",
    "aser.sort_values(ascending=False, inplace=True)\n",
    "aser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create another Series with a slightly different index, notice how we can set the type of the data\n",
    "data = [np.random.randint(-200, 200) for i in range(5)]\n",
    "bser = pd.Series(data, index=list('bcdef'), dtype=np.dtype('int16'), name='B')\n",
    "bser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add the two series together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "aser + bser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is **intrinsically** aligned on the index.  `aser` does not have a value at label `f` and `bser` has no value for label `a` thus in the sum these both get `NaN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataFrame` is a 2D data structure contains one or more 1D data arrays or Series, each with its own data type.  A minimal `DataFrame` constructor looks like:\n",
    "```\n",
    "df = pd.DataFrame(data, columns, index)\n",
    "```\n",
    "where `data` can be\n",
    "\n",
    "- a `dict` of 1D `np.ndarray`s, `list`, `dict` or `Series`: the `dict` keys are used as the column names\n",
    "- a 2D `np.ndarray`\n",
    "- a structured or record `np.ndarray`\n",
    "- a `pd.Series`\n",
    "- another `DataFrame`\n",
    "\n",
    "The `index` is not required, but if provided it must be the same length as the provided data.  If an `index` is not provided a zero based integer index is created based on the size of the data.  The column names are taken from the `columns` input list (if provided) or the key values if a `dict` is used as the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create from a dict of mixed data\n",
    "df = pd.DataFrame({'A': aser, 'B': bser, 'C': [3]*6})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Select a single column, result is a Series\n",
    "df['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Select multiple columns, result is a DataFrame, NOTE: use list\n",
    "df[['C', 'B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Select a row by label, result is a Series\n",
    "df.loc['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Select a subset of rows, result is a DataFrame\n",
    "df.iloc[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Select based on a boolean condition\n",
    "df[df['A'] < 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment/Deletion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Assign to an known column\n",
    "df['C'] = 5\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Assign to an unknown column creates a new column (at end by default)\n",
    "df['D'] = df['A']*100\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Delete a column\n",
    "del df['D']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dump all values out as a numpy array, widest type (float64) is chosen\n",
    "npdata = df.values\n",
    "print(f\"Data type for array {npdata.dtype}, integer types cast to this type\")\n",
    "npdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date/Time Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dt = pd.to_datetime('2024-06-30 15:00:00', utc=True)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Datetime in nanoseconds \n",
    "dt.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(1465570900000000, unit='us', utc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DatetimeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dt_index = pd.date_range('2024-06-30 15:00:00', periods=100, freq='10s')\n",
    "df = pd.DataFrame(np.random.randn(100, 4), columns=list('ABCD'), index=dt_index)\n",
    "df.head()  # Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Select based on timestamp, NOTE: includes the last timestamp\n",
    "df['2024-06-30 15:01:00':'2024-06-30 15:02:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.loc['2024-06-30 15:01:00':'2024-06-30 15:02:00', ['C', 'B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data\n",
    "\n",
    "The first thing we need to do is get some data.  Pandas is VERY flexible and provides a plethora of ways to read data.   You can read from flat files (CSV, text, HTML, XML), databases, HDF5, Parquet, SPSS.  Pandas has you covered in reading data.   Since it is easiest I'm going to use CSV files\n",
    "\n",
    "- Reference the [Pandas Input/Output documentation](https://pandas.pydata.org/pandas-docs/stable/reference/io.html) for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia_data_file = Path.cwd() / 'data' / 'nvidia.csv'\n",
    "nvda_prices = pd.read_csv(nvidia_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvda_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty basic import, let's see if pandas can help us a little more.  The `read_csv` [method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html#pandas.read_csv) has about 30 kwargs to help so let's use a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvda_prices = pd.read_csv(nvidia_data_file,\n",
    "                          parse_dates=['Date'], # parse dates in one (or more columns)\n",
    "                          index_col='Date',\n",
    "                         )\n",
    "nvda_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvda_prices.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvda_prices.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvda_prices['Close'].plot(grid=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvda_prices.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvda_prices.nlargest(columns=['Close'], n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvda_prices.nsmallest(columns=['Close'], n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Filtering and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa_file = Path.cwd() / 'data' / 'fifa_players_22.csv'\n",
    "players = pd.read_csv(fifa_file, low_memory=False)\n",
    "players.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note pandas does the best job it can to get the data type for the field right\n",
    "print(f\"Player age column type: {players['age'].dtype}\")\n",
    "print(f\"Player name column type: {players['short_name'].dtype}\")   # object is default for string\n",
    "print(f\"Player gk rating column type: {players['gk'].dtype}\")      # this isn't exactly what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_select= ['short_name', 'overall', 'nationality_name', 'player_positions', 'age', 'preferred_foot', 'club_name', 'gk']\n",
    "players[columns_to_select].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see if we can filter thisd donw a little bit, since strikers get all the glory\n",
    "center_backs_only = players['player_positions'] == 'CB'\n",
    "players[center_backs_only][columns_to_select].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_backs_only = players['player_positions'] == 'CB'\n",
    "right_backs_only = players['player_positions'] == 'RB'\n",
    "left_backs_only = players['player_positions'] == 'LB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players[center_backs_only | right_backs_only | left_backs_only ][columns_to_select].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is shows some of the power of boolean indexing in pandas, we create a boolean index and can combine those indices using additional boolean logic to build complicated expressions.  There is a problem though with some of this position data.  Some players play multiple positions see Messi or Neymar Jr.  If we wanted to focus on all the players for a specific position we'd need to include these.  How do we create an expression for that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdm_players_mask = players['player_positions'].str.contains('CDM')\n",
    "cdm_players = players[cdm_players_mask]\n",
    "cdm_players[columns_to_select].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we only want the younger players say <= 25\n",
    "max_age = 25\n",
    "young_cdm_players = players[cdm_players_mask & (players['age'] <= max_age)]\n",
    "young_cdm_players[columns_to_select].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(players['gk'].str.contains('\\\\+').all())    # have to use `\\\\+` for regular expression\n",
    "gk_rating_data = players['gk'].str.split('+')\n",
    "np_data = np.array([[int(x), int(y)] for x, y in gk_rating_data.values])\n",
    "players['gk'] = np_data[:, 0] + np_data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about the best outfield player to with the highest GK rating\n",
    "outfield_player_mask = players['player_positions'] != 'GK'\n",
    "outfield_players = players[outfield_player_mask]\n",
    "outfield_players[columns_to_select].sort_values(by=['gk'], ascending=False).head()                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_by_nation = players.groupby(['nationality_name'])         # NOTE: the [ ] are very important here, must be a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grp_by_nation) == players[['nationality_name']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grp_by_nation.groups  (oodles and gobs of nearly unreadable data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_by_nation.size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_player = grp_by_nation.first()\n",
    "top_player[['short_name', 'overall', 'player_positions', 'age', 'preferred_foot', 'club_name']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the 5th best player for their naition\n",
    "nth_player = grp_by_nation.nth(5)\n",
    "nth_player[columns_to_select].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nation = 'Georgia'\n",
    "nat_players = grp_by_nation.get_group((nation,))\n",
    "nat_players[columns_to_select].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_grp = players.groupby(['player_positions', 'nationality_name'])       \n",
    "multi_grp.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_grp.get_group(('CDM', :)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging, Joining and Contatenating (OH MY....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "24*2*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
